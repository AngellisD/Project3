{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Trying with my classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as ts\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras import \n",
    "from keras.callbacks import CSVLogger\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVOLUTIONAL AUTOENCODER\n",
    "\n",
    "input_img = Input(shape=(64, 64, 3))\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img) #16\n",
    "x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x) #8\n",
    "x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "encoded = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "                \n",
    "x = Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(encoded)\n",
    "x = Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously saved images using get_training_data function (can be found at the end of notebook)\n",
    "\n",
    "images = np.load('humans_64.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype('float32') / 255.\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = images[0:5000]\n",
    "x_test = images[5000:6500]\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), 64, 64, 3))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 64, 64, 3))  # adapt this if using `channels_first` image data format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TO SAVE MEMORY\n",
    "\n",
    "images=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_model('model2-final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss\n",
    "\n",
    "def custom_loss(layer):           \n",
    "     \n",
    "    def loss(y_true, y_pred):       \n",
    "\n",
    "        class_pred = classifier(y_pred)\n",
    "\n",
    "        pred_print = ts.Print(class_pred, [class_pred], 'resnet pred: ') # PRINTS TO TERMINAL\n",
    "        \n",
    "        \n",
    "        autoencoder_loss = losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        autoencoder_mean = ts.math.reduce_mean(autoencoder_loss, [1, 2])\n",
    "       \n",
    "        alpha = 1\n",
    "        \n",
    "        final_loss = autoencoder_mean + alpha * (ts.stop_gradient(pred_print))\n",
    "        \n",
    "        return final_loss\n",
    "  \n",
    "\n",
    "    return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE MODEL\n",
    "doggifier = Model(input_img, decoded)\n",
    "batch_size= 128\n",
    "\n",
    "\n",
    "doggifier.compile(optimizer='adadelta',\n",
    "              loss=custom_loss(decoded), # Call the loss function with the selected layer\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TRAIN MODEL\n",
    "\n",
    "TRAINING_LOGS_FILE = 'auto-our-classif-training.csv'\n",
    "\n",
    "epochs=50\n",
    "\n",
    "for j in range(epochs):\n",
    "    \n",
    "    print(f'Running epoch {j+1}/{epochs}')\n",
    "    \n",
    "    doggifier.fit(x_train, x_train,\n",
    "                epochs=1,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                callbacks=[ CSVLogger(TRAINING_LOGS_FILE, append=False, separator=\";\")])\n",
    "    \n",
    "    epoch_number = j+1\n",
    "    \n",
    "    decoded_imgs = doggifier.predict(x_test)\n",
    "    \n",
    "    n = 4\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(x_test[i].reshape(64, 64,3))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i +1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(64, 64,3))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    fig_name = f'fig_epoch{j}-auto-our-classif.png'\n",
    "    plt.savefig(fig_name)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggifier.save('doggif_our_classif.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on another set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs2 = get_training_data('../data/test2/human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs2 = imgs2.astype('float32') / 255.\n",
    "imgs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded2 = doggifier.predict(imgs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(imgs2[i].reshape(64, 64,3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i +1 + n)\n",
    "    plt.imshow(decoded2[i].reshape(64, 64,3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_training_data(datafolder):\n",
    "        print(\"Loading training data...\")\n",
    "\n",
    "        training_data = []\n",
    "        #Finds all files in datafolder\n",
    "        foldernames = os.listdir(datafolder)\n",
    "#         print(foldernames)\n",
    "        for foldername in tqdm(foldernames):\n",
    "            folder_path = os.path.join(datafolder, foldername)\n",
    "            filenames = os.listdir(folder_path)\n",
    "            folder = foldername\n",
    "            for filename in tqdm(filenames):\n",
    "                \n",
    "                #Combines folder name and file name.\n",
    "                path = os.path.join(datafolder,folder, filename)\n",
    "                print(path)\n",
    "                \n",
    "                #Opens an image as an Image object.\n",
    "                image = Image.open(path)\n",
    "                \n",
    "                #Resizes to a desired size.\n",
    "                image = image.resize((64,64),Image.ANTIALIAS)\n",
    "                \n",
    "                #Creates an array of pixel values from the image.\n",
    "                pixel_array = np.asarray(image)\n",
    "#                 print(type(pixel_array))\n",
    "                print(pixel_array.shape)\n",
    "                training_data.append(pixel_array)\n",
    "\n",
    "        #training_data is converted to a numpy array\n",
    "        training_data = np.asarray(training_data)\n",
    "#         training_data = np.reshape(training_data,(-1,64,64,1))\n",
    "        return training_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
